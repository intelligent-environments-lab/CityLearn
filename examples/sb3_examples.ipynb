{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable Baselines 3 Examples with CityLearn\n",
    "The `WARNING:root:The StableBaselines3Wrapper wrapper is compatible only when env.central_agent=True. Note that env.central_agent has been set to True for compatibility.` is normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install stable-baselines3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The StableBaselines3Wrapper wrapper is compatible only when env.central_agent=True. Note that env.central_agent has been set to True for compatibility.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test!! CityLearn is compatible with SB3 when using the StableBaselines3Wrapper.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "from citylearn.wrappers import StableBaselines3ActionWrapper\n",
    "\n",
    "# Initialize environment\n",
    "dataset_name = 'citylearn_challenge_2022_phase_1'\n",
    "env = CityLearnEnv(dataset_name)\n",
    "\n",
    "# Wrap for SB3 compatibility\n",
    "env = StableBaselines3Wrapper(env)\n",
    "\n",
    "# Perform compatibility check\n",
    "try:\n",
    "    check_env(env)\n",
    "    print('Passed test!! CityLearn is compatible with SB3 when using the StableBaselines3Wrapper.')\n",
    "finally:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 301      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.12    |\n",
      "|    explained_variance | 0.0609   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -43.2    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 43.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 311      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.13    |\n",
      "|    explained_variance | 0.00147  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -80.5    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 155      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 319      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.13    |\n",
      "|    explained_variance | 0.00906  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -111     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 290      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 322      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.14    |\n",
      "|    explained_variance | 0.00149  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -127     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 318      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 325       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.1      |\n",
      "|    explained_variance | -0.000365 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -51.4     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 81.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 326      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.11    |\n",
      "|    explained_variance | -0.00784 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -15.2    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 9.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 327      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.12    |\n",
      "|    explained_variance | -0.00202 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -3.75    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 2.28     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 327      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.13    |\n",
      "|    explained_variance | 0.00013  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -23.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 33       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 328      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.1     |\n",
      "|    explained_variance | 0.00056  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -117     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 199      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 328       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.11     |\n",
      "|    explained_variance | -1.53e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | -177      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 882       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 16       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.11    |\n",
      "|    explained_variance | 4.04e-05 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -106     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 312      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 328      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.1     |\n",
      "|    explained_variance | 0.708    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -28.3    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 17.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 329      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.1     |\n",
      "|    explained_variance | 0.518    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -1.87    |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 0.319    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 330      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.09    |\n",
      "|    explained_variance | -8.46    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 22.6     |\n",
      "|    std                | 1        |\n",
      "|    value_loss         | 15.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 331      |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 22       |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.08    |\n",
      "|    explained_variance | 0.157    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -1.93    |\n",
      "|    std                | 0.998    |\n",
      "|    value_loss         | 13.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 331       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.08     |\n",
      "|    explained_variance | -2.94e-05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -79.4     |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 149       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 331       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.06     |\n",
      "|    explained_variance | -0.000939 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | -112      |\n",
      "|    std                | 0.994     |\n",
      "|    value_loss         | 347       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.76e+03  |\n",
      "|    ep_rew_mean        | -3.25e+04 |\n",
      "| time/                 |           |\n",
      "|    fps                | 332       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.06     |\n",
      "|    explained_variance | -0.0126   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -78.8     |\n",
      "|    std                | 0.994     |\n",
      "|    value_loss         | 164       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 8.76e+03  |\n",
      "|    ep_rew_mean        | -3.25e+04 |\n",
      "| time/                 |           |\n",
      "|    fps                | 333       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.06     |\n",
      "|    explained_variance | 0.527     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | -2.75     |\n",
      "|    std                | 0.994     |\n",
      "|    value_loss         | 0.679     |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import A2C\n",
    "# Run simulation with A2C policy\n",
    "model = A2C(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=17520)\n",
    "# Evaluation\n",
    "print(env.evaluate())\n",
    "# Reset\n",
    "env.reset()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAC SB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 8.76e+03  |\n",
      "|    ep_rew_mean     | -3.01e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 695       |\n",
      "|    time_elapsed    | 50        |\n",
      "|    total_timesteps | 35036     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 80.5      |\n",
      "|    critic_loss     | 943       |\n",
      "|    ent_coef        | 1         |\n",
      "|    ent_coef_loss   | -0.0181   |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 3         |\n",
      "----------------------------------\n",
      "              cost_function         value        name     level\n",
      "0           1 - load_factor  1.297357e+00    District  district\n",
      "1        average_daily_peak  3.062132e+00    District  district\n",
      "2          carbon_emissions  2.734781e+06    District  district\n",
      "3   electricity_consumption  2.744014e+06    District  district\n",
      "4               peak_demand  3.062132e+00    District  district\n",
      "5                   pricing  2.744014e+06    District  district\n",
      "6                   ramping  6.165464e+00    District  district\n",
      "7           zero_net_energy  2.744011e+06    District  district\n",
      "8   electricity_consumption  2.105695e+00  Building_1  building\n",
      "9           zero_net_energy  2.105695e+00  Building_1  building\n",
      "10         carbon_emissions  2.084041e+00  Building_1  building\n",
      "11                  pricing  2.105695e+00  Building_1  building\n",
      "12  electricity_consumption  2.323074e+00  Building_2  building\n",
      "13          zero_net_energy  2.243588e+00  Building_2  building\n",
      "14         carbon_emissions  2.285387e+00  Building_2  building\n",
      "15                  pricing  2.323074e+00  Building_2  building\n",
      "16  electricity_consumption  1.372006e+07  Building_3  building\n",
      "17          zero_net_energy  1.372004e+07  Building_3  building\n",
      "18         carbon_emissions  1.367389e+07  Building_3  building\n",
      "19                  pricing  1.372006e+07  Building_3  building\n",
      "20  electricity_consumption  2.481573e+00  Building_4  building\n",
      "21          zero_net_energy  1.244803e+00  Building_4  building\n",
      "22         carbon_emissions  2.407081e+00  Building_4  building\n",
      "23                  pricing  2.481573e+00  Building_4  building\n",
      "24  electricity_consumption  3.282100e+00  Building_5  building\n",
      "25          zero_net_energy  2.126205e+00  Building_5  building\n",
      "26         carbon_emissions  3.216556e+00  Building_5  building\n",
      "27                  pricing  3.282100e+00  Building_5  building\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7.0000000e+00, 7.0000000e+00, 2.4000000e+01, 2.0000000e+01,\n",
       "       1.8299999e+01, 2.2799999e+01, 2.0000000e+01, 8.4000000e+01,\n",
       "       8.1000000e+01, 6.8000000e+01, 8.1000000e+01, 0.0000000e+00,\n",
       "       2.5000000e+01, 9.6400000e+02, 0.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+02, 8.1500000e+02, 0.0000000e+00, 1.7072441e-01,\n",
       "       2.2758000e+00, 0.0000000e+00, 0.0000000e+00, 2.2758000e+00,\n",
       "       2.2000000e-01, 2.2000000e-01, 2.2000000e-01, 2.2000000e-01,\n",
       "       2.1887500e+00, 0.0000000e+00, 0.0000000e+00, 2.1887500e+00,\n",
       "       2.2000000e-01, 2.2000000e-01, 2.2000000e-01, 2.2000000e-01,\n",
       "       1.0096232e-07, 0.0000000e+00, 0.0000000e+00, 1.0096232e-07,\n",
       "       2.2000000e-01, 2.2000000e-01, 2.2000000e-01, 2.2000000e-01,\n",
       "       2.8191500e+00, 0.0000000e+00, 0.0000000e+00, 2.8191500e+00,\n",
       "       2.2000000e-01, 2.2000000e-01, 2.2000000e-01, 2.2000000e-01,\n",
       "       7.7143335e-01, 0.0000000e+00, 0.0000000e+00, 7.7143335e-01,\n",
       "       2.2000000e-01, 2.2000000e-01, 2.2000000e-01, 2.2000000e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import SAC\n",
    "# Run simulation with SAC policy\n",
    "# train_freq is episode\n",
    "\"\"\"\n",
    ":param train_freq: Update the model every ``train_freq`` steps. Alternatively pass a tuple of frequency and unit\n",
    "        like ``(5, \"step\")`` or ``(2, \"episode\")``.\n",
    "\"\"\"\n",
    "model = SAC('MlpPolicy', env, verbose=1, seed=0, train_freq=8760)\n",
    "model.learn(total_timesteps=35040, log_interval=4)\n",
    "# Evaluation\n",
    "print(env.evaluate())\n",
    "# Reset\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "              cost_function     value        name     level\n",
      "0           1 - load_factor  1.095234    District  district\n",
      "1        average_daily_peak  1.820688    District  district\n",
      "2          carbon_emissions  1.718907    District  district\n",
      "3   electricity_consumption  1.730628    District  district\n",
      "4               peak_demand  1.820688    District  district\n",
      "5                   pricing  1.730628    District  district\n",
      "6                   ramping  3.104033    District  district\n",
      "7           zero_net_energy  1.730628    District  district\n",
      "8   electricity_consumption  1.000000  Building_1  building\n",
      "9           zero_net_energy  1.000000  Building_1  building\n",
      "10         carbon_emissions  1.000000  Building_1  building\n",
      "11                  pricing  1.000000  Building_1  building\n",
      "12  electricity_consumption  2.207949  Building_2  building\n",
      "13          zero_net_energy  2.207949  Building_2  building\n",
      "14         carbon_emissions  2.176152  Building_2  building\n",
      "15                  pricing  2.207949  Building_2  building\n",
      "16  electricity_consumption  1.000000  Building_3  building\n",
      "17          zero_net_energy  1.000000  Building_3  building\n",
      "18         carbon_emissions  1.000000  Building_3  building\n",
      "19                  pricing  1.000000  Building_3  building\n",
      "20  electricity_consumption  1.000000  Building_4  building\n",
      "21          zero_net_energy  1.000000  Building_4  building\n",
      "22         carbon_emissions  1.000000  Building_4  building\n",
      "23                  pricing  1.000000  Building_4  building\n",
      "24  electricity_consumption  3.445193  Building_5  building\n",
      "25          zero_net_energy  3.445193  Building_5  building\n",
      "26         carbon_emissions  3.418385  Building_5  building\n",
      "27                  pricing  3.445193  Building_5  building\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7.0000000e+00, 7.0000000e+00, 2.4000000e+01, 2.0000000e+01,\n",
       "       1.8299999e+01, 2.2799999e+01, 2.0000000e+01, 8.4000000e+01,\n",
       "       8.1000000e+01, 6.8000000e+01, 8.1000000e+01, 0.0000000e+00,\n",
       "       2.5000000e+01, 9.6400000e+02, 0.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+02, 8.1500000e+02, 0.0000000e+00, 1.7072441e-01,\n",
       "       2.2758000e+00, 0.0000000e+00, 0.0000000e+00, 2.2758000e+00,\n",
       "       2.2000000e-01, 2.2000000e-01, 2.2000000e-01, 2.2000000e-01,\n",
       "       2.1887500e+00, 0.0000000e+00, 0.0000000e+00, 2.1887500e+00,\n",
       "       2.2000000e-01, 2.2000000e-01, 2.2000000e-01, 2.2000000e-01,\n",
       "       1.0096232e-07, 0.0000000e+00, 0.0000000e+00, 1.0096232e-07,\n",
       "       2.2000000e-01, 2.2000000e-01, 2.2000000e-01, 2.2000000e-01,\n",
       "       2.8191500e+00, 0.0000000e+00, 0.0000000e+00, 2.8191500e+00,\n",
       "       2.2000000e-01, 2.2000000e-01, 2.2000000e-01, 2.2000000e-01,\n",
       "       7.7143335e-01, 0.0000000e+00, 0.0000000e+00, 7.7143335e-01,\n",
       "       2.2000000e-01, 2.2000000e-01, 2.2000000e-01, 2.2000000e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import TD3\n",
    "# Run simulation with TD3 Policy\n",
    "model = TD3(\"MlpPolicy\", env, verbose=1, train_freq=8760)\n",
    "model.learn(total_timesteps=17520, log_interval=10)\n",
    "# Evaluation\n",
    "print(env.evaluate())\n",
    "# Reset\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 518  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 3    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 442          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080549605 |\n",
      "|    clip_fraction        | 0.0706       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.08        |\n",
      "|    explained_variance   | -0.00999     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.09e+03     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0156      |\n",
      "|    std                  | 0.994        |\n",
      "|    value_loss           | 4.53e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 420          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071160514 |\n",
      "|    clip_fraction        | 0.0548       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.04        |\n",
      "|    explained_variance   | -0.00231     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.48e+03     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0171      |\n",
      "|    std                  | 0.987        |\n",
      "|    value_loss           | 5.18e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 407         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009531227 |\n",
      "|    clip_fraction        | 0.0784      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.03       |\n",
      "|    explained_variance   | -5.41e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.25e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    std                  | 0.988       |\n",
      "|    value_loss           | 4.57e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 8.76e+03     |\n",
      "|    ep_rew_mean          | -3.67e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 401          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0092636235 |\n",
      "|    clip_fraction        | 0.0942       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -7.02        |\n",
      "|    explained_variance   | 0.000181     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0164      |\n",
      "|    std                  | 0.984        |\n",
      "|    value_loss           | 3.04e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | -3.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 400         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007958541 |\n",
      "|    clip_fraction        | 0.0706      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.01       |\n",
      "|    explained_variance   | 9.75e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.3e+03     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 4.91e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | -3.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009994814 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7          |\n",
      "|    explained_variance   | -2.38e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.53e+03    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    std                  | 0.978       |\n",
      "|    value_loss           | 3.5e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | -3.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 398         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009738373 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.98       |\n",
      "|    explained_variance   | -1e-05      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.29e+03    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    std                  | 0.975       |\n",
      "|    value_loss           | 5.16e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 8.76e+03    |\n",
      "|    ep_rew_mean          | -3.65e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 395         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013276629 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -6.95       |\n",
      "|    explained_variance   | -4.89e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 643         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    std                  | 0.971       |\n",
      "|    value_loss           | 1.63e+03    |\n",
      "-----------------------------------------\n",
      "              cost_function     value        name     level\n",
      "0           1 - load_factor  1.050430    District  district\n",
      "1        average_daily_peak  1.588962    District  district\n",
      "2          carbon_emissions  1.728648    District  district\n",
      "3   electricity_consumption  1.741705    District  district\n",
      "4               peak_demand  1.824847    District  district\n",
      "5                   pricing  1.643912    District  district\n",
      "6                   ramping  3.641783    District  district\n",
      "7           zero_net_energy  1.238833    District  district\n",
      "8   electricity_consumption  1.436652  Building_1  building\n",
      "9           zero_net_energy  1.181496  Building_1  building\n",
      "10         carbon_emissions  1.412264  Building_1  building\n",
      "11                  pricing  1.341652  Building_1  building\n",
      "12  electricity_consumption  1.723510  Building_2  building\n",
      "13          zero_net_energy  1.243026  Building_2  building\n",
      "14         carbon_emissions  1.715966  Building_2  building\n",
      "15                  pricing  1.673526  Building_2  building\n",
      "16  electricity_consumption  1.628462  Building_3  building\n",
      "17          zero_net_energy  1.217142  Building_3  building\n",
      "18         carbon_emissions  1.650156  Building_3  building\n",
      "19                  pricing  1.543317  Building_3  building\n",
      "20  electricity_consumption  1.978851  Building_4  building\n",
      "21          zero_net_energy  1.273559  Building_4  building\n",
      "22         carbon_emissions  2.012149  Building_4  building\n",
      "23                  pricing  2.004535  Building_4  building\n",
      "24  electricity_consumption  1.941050  Building_5  building\n",
      "25          zero_net_energy  1.278942  Building_5  building\n",
      "26         carbon_emissions  1.852702  Building_5  building\n",
      "27                  pricing  1.656532  Building_5  building\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7.0000000e+00, 7.0000000e+00, 2.4000000e+01, 2.0000000e+01,\n",
       "       1.8299999e+01, 2.2799999e+01, 2.0000000e+01, 8.4000000e+01,\n",
       "       8.1000000e+01, 6.8000000e+01, 8.1000000e+01, 0.0000000e+00,\n",
       "       2.5000000e+01, 9.6400000e+02, 0.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+02, 8.1500000e+02, 0.0000000e+00, 1.7072441e-01,\n",
       "       2.2758000e+00, 0.0000000e+00, 0.0000000e+00, 2.2758000e+00,\n",
       "       2.2000000e-01, 2.2000000e-01, 2.2000000e-01, 2.2000000e-01,\n",
       "       2.1887500e+00, 0.0000000e+00, 0.0000000e+00, 2.1887500e+00,\n",
       "       2.2000000e-01, 2.2000000e-01, 2.2000000e-01, 2.2000000e-01,\n",
       "       1.0096232e-07, 0.0000000e+00, 0.0000000e+00, 1.0096232e-07,\n",
       "       2.2000000e-01, 2.2000000e-01, 2.2000000e-01, 2.2000000e-01,\n",
       "       2.8191500e+00, 0.0000000e+00, 0.0000000e+00, 2.8191500e+00,\n",
       "       2.2000000e-01, 2.2000000e-01, 2.2000000e-01, 2.2000000e-01,\n",
       "       7.7143335e-01, 0.0000000e+00, 0.0000000e+00, 7.7143335e-01,\n",
       "       2.2000000e-01, 2.2000000e-01, 2.2000000e-01, 2.2000000e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "# Run simulation with PPO Policy\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=17520)\n",
    "# Evaluation\n",
    "print(env.evaluate())\n",
    "# Reset\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "              cost_function     value        name     level\n",
      "0           1 - load_factor  0.932296    District  district\n",
      "1        average_daily_peak  1.820688    District  district\n",
      "2          carbon_emissions  2.001118    District  district\n",
      "3   electricity_consumption  2.041263    District  district\n",
      "4               peak_demand  1.820688    District  district\n",
      "5                   pricing  2.041263    District  district\n",
      "6                   ramping  2.816585    District  district\n",
      "7           zero_net_energy  2.041263    District  district\n",
      "8   electricity_consumption  1.000000  Building_1  building\n",
      "9           zero_net_energy  1.000000  Building_1  building\n",
      "10         carbon_emissions  1.000000  Building_1  building\n",
      "11                  pricing  1.000000  Building_1  building\n",
      "12  electricity_consumption  1.000000  Building_2  building\n",
      "13          zero_net_energy  1.000000  Building_2  building\n",
      "14         carbon_emissions  1.000000  Building_2  building\n",
      "15                  pricing  1.000000  Building_2  building\n",
      "16  electricity_consumption  1.000000  Building_3  building\n",
      "17          zero_net_energy  1.000000  Building_3  building\n",
      "18         carbon_emissions  1.000000  Building_3  building\n",
      "19                  pricing  1.000000  Building_3  building\n",
      "20  electricity_consumption  2.329039  Building_4  building\n",
      "21          zero_net_energy  2.329039  Building_4  building\n",
      "22         carbon_emissions  2.266213  Building_4  building\n",
      "23                  pricing  2.329039  Building_4  building\n",
      "24  electricity_consumption  4.877277  Building_5  building\n",
      "25          zero_net_energy  4.877277  Building_5  building\n",
      "26         carbon_emissions  4.739376  Building_5  building\n",
      "27                  pricing  4.877277  Building_5  building\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7.0000000e+00, 7.0000000e+00, 2.4000000e+01, 2.0000000e+01,\n",
       "       1.8299999e+01, 2.2799999e+01, 2.0000000e+01, 8.4000000e+01,\n",
       "       8.1000000e+01, 6.8000000e+01, 8.1000000e+01, 0.0000000e+00,\n",
       "       2.5000000e+01, 9.6400000e+02, 0.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+02, 8.1500000e+02, 0.0000000e+00, 1.7072441e-01,\n",
       "       2.2758000e+00, 0.0000000e+00, 0.0000000e+00, 2.2758000e+00,\n",
       "       2.2000000e-01, 2.2000000e-01, 2.2000000e-01, 2.2000000e-01,\n",
       "       2.1887500e+00, 0.0000000e+00, 0.0000000e+00, 2.1887500e+00,\n",
       "       2.2000000e-01, 2.2000000e-01, 2.2000000e-01, 2.2000000e-01,\n",
       "       1.0096232e-07, 0.0000000e+00, 0.0000000e+00, 1.0096232e-07,\n",
       "       2.2000000e-01, 2.2000000e-01, 2.2000000e-01, 2.2000000e-01,\n",
       "       2.8191500e+00, 0.0000000e+00, 0.0000000e+00, 2.8191500e+00,\n",
       "       2.2000000e-01, 2.2000000e-01, 2.2000000e-01, 2.2000000e-01,\n",
       "       7.7143335e-01, 0.0000000e+00, 0.0000000e+00, 7.7143335e-01,\n",
       "       2.2000000e-01, 2.2000000e-01, 2.2000000e-01, 2.2000000e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import DDPG\n",
    "# Run simulation with DDPG Policy\n",
    "model = DDPG(\"MlpPolicy\", env, verbose=1, train_freq=8760)\n",
    "model.learn(total_timesteps=17520, log_interval=10)\n",
    "# Evaluation\n",
    "print(env.evaluate())\n",
    "# Reset\n",
    "env.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a880801d82842a837e5fe4ed3b68ee317975c448dafb42226406b8e2a6a4c5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
